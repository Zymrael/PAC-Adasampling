# PAC-Adasampling
An implementation of the algorithm proposed in 'A PAC-Bayesian Analysis of Randomized Learning with Application to Stochastic Gradient Descent', Ben London (NIPS 2017)

A faster way for your neural nets to converge. Based on a PAC-Bayesian analysis of generalization bounds.

![algo](resources/algo1.png)

From the paper at (https://arxiv.org/abs/1709.06617)

## Dataset

The tests are performed on the Case Western Reserve University (CWRU) fault classification dataset. Slightly more challenging than MNIST:
![link](https://csegroups.case.edu/bearingdatacenter/pages/welcome-case-western-reserve-university-bearing-data-center-website)
